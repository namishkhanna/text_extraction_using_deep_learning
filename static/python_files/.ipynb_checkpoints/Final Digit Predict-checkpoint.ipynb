{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda\\envs\\ml\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import cv2, os, glob\n",
    "from PIL import Image \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.datasets.mnist import load_data\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # threshold the image into white and black pixel values only\n",
    "    th3 = cv2.adaptiveThreshold(resized ,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "    \n",
    "    # return the resized image\n",
    "    return th3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image):\n",
    "    im = image\n",
    "    # smooth the image with alternative closing and opening\n",
    "    # with an enlarging kernel\n",
    "    morph = im.copy()\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_CLOSE, kernel)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "\n",
    "    # take morphological gradient\n",
    "    gradient_image = cv2.morphologyEx(morph, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "    # split the gradient image into channels\n",
    "    image_channels = np.split(np.asarray(gradient_image), 3, axis=2)\n",
    "\n",
    "    channel_height, channel_width, _ = image_channels[0].shape\n",
    "\n",
    "    # apply Otsu threshold to each channel\n",
    "    for i in range(0, 3):\n",
    "        _, image_channels[i] = cv2.threshold(~image_channels[i], 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "        image_channels[i] = np.reshape(image_channels[i], newshape=(channel_height, channel_width, 1))\n",
    "\n",
    "    # merge the channels\n",
    "    image_channels = np.concatenate((image_channels[0], image_channels[1], image_channels[2]), axis=2)\n",
    "    \n",
    "    # convert the image to greyscale\n",
    "    image  = cv2.cvtColor(image_channels, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # return the image\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-748d15a62c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_pickle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../model\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_pickle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../model'"
     ]
    }
   ],
   "source": [
    "final_pickle = open(\"../model\",\"rb\")\n",
    "final_model = pkl.load(final_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the image name: 1.png\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-edc68a42b156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_to_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_to_predict\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_to_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_resize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimg_grey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-246aa7bfc32c>\u001b[0m in \u001b[0;36mremove_noise\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# smooth the image with alternative closing and opening\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# with an enlarging kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmorph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPH_RECT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "file_to_predict = \"../DATA/files/\"\n",
    "file_name = input(\"Enter the image name: \")\n",
    "file_to_predict = file_to_predict+file_name\n",
    "img = cv2.imread(file_to_predict)\n",
    "img = remove_noise(img)\n",
    "img = image_resize(img, height = 28, width = 28)\n",
    "img_grey = cv2.resize(img,(28,28))\n",
    "img_grey = cv2.adaptiveThreshold(img_grey ,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "#img_grey = 255-img_grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_grey)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grey = img_grey.reshape(-1,28,28,1)\n",
    "img_grey = img_grey//255\n",
    "y_preds = np.argmax(final_model.predict(img_grey),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
